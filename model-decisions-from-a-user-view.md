# When AI says "no", what should users see?

Problem:
AI systems often reject actions without explanation.

Bad outcomes:
- User frustration
- Support escalation
- Regulatory exposure

Better design:
- Actionable explanations
- Confidence indicators
- Escalation paths
